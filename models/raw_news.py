"""Data models for raw news items."""
from typing import Optional, Dict, Any
from pydantic import BaseModel, Field
from datetime import datetime, timezone, timedelta
from enum import Enum
import hashlib
import json

# EST timezone (UTC-5) - for display only
EST = timezone(timedelta(hours=-5))
UTC = timezone.utc


class ProcessingStatus(str, Enum):
    """Processing status for raw news items."""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


class RawNewsItem(BaseModel):
    """Raw news item model for data lake storage."""

    # Identifiers
    id: Optional[str] = Field(None, description="UUID generated by database")
    symbol: str = Field(..., description="Stock ticker symbol")

    # Raw data
    raw_html: Optional[str] = Field(None, description="HTML from web scraping")
    raw_json: Optional[Dict[str, Any]] = Field(None, description="JSON from APIs")

    # Metadata
    url: str = Field(..., description="Source URL")
    fetch_source: str = Field(..., description="Source API (finnhub, polygon, etc.)")
    fetched_at: datetime = Field(default_factory=datetime.now, description="When fetched")
    published_at: Optional[datetime] = Field(None, description="Actual news publication time")

    # Processing state
    is_processed: bool = Field(default=False, description="Processing flag")
    processed_at: Optional[datetime] = Field(None, description="When processed")
    processing_status: ProcessingStatus = Field(
        default=ProcessingStatus.PENDING,
        description="Processing status"
    )
    error_log: Optional[str] = Field(None, description="Error messages")

    # Additional fields
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
    content_hash: Optional[str] = Field(None, description="Deduplication hash")

    # Timestamps
    created_at: datetime = Field(default_factory=datetime.now, description="Creation timestamp")
    updated_at: datetime = Field(default_factory=datetime.now, description="Last update")

    def generate_content_hash(self) -> str:
        """
        Generate MD5 hash of URL for deduplication.

        Returns:
            MD5 hash string
        """
        return hashlib.md5(self.url.encode()).hexdigest()

    def to_db_dict(self) -> Dict[str, Any]:
        """
        Convert to dictionary for database insertion.

        Returns:
            Dictionary with database-compatible fields
        """
        # Generate content hash if not exists
        if not self.content_hash:
            self.content_hash = self.generate_content_hash()

        return {
            "symbol": self.symbol.upper(),
            "raw_html": self.raw_html,
            "raw_json": self.raw_json,
            "url": self.url,
            "fetch_source": self.fetch_source,
            "fetched_at": self.fetched_at.isoformat(),
            "published_at": self.published_at.isoformat() if self.published_at else None,
            "is_processed": self.is_processed,
            "processed_at": self.processed_at.isoformat() if self.processed_at else None,
            "processing_status": self.processing_status.value,
            "error_log": self.error_log,
            "metadata": self.metadata,
            "content_hash": self.content_hash,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
        }

    @classmethod
    def from_finnhub_response(
        cls,
        symbol: str,
        article_data: Dict[str, Any],
        category: str = "general"
    ) -> "RawNewsItem":
        """
        Create RawNewsItem from Finnhub API response.

        Args:
            symbol: Stock ticker symbol
            article_data: Article data from Finnhub
            category: Finnhub category (general, merger, forex, crypto)

        Returns:
            RawNewsItem instance
        """
        # Extract published_at from Finnhub's 'datetime' field (Unix timestamp in UTC)
        # Store as naive UTC (Supabase will treat as UTC)
        published_at = None
        if 'datetime' in article_data:
            published_at = datetime.fromtimestamp(article_data['datetime'], tz=UTC).replace(tzinfo=None)

        return cls(
            symbol=symbol.upper(),
            raw_json=article_data,
            url=article_data.get("url", ""),
            fetch_source=f"finnhub_{category}",
            published_at=published_at,
            metadata={
                "external_id": str(article_data.get("id", "")),
                "category": article_data.get("category", ""),
                "source": article_data.get("source", ""),
                "image": article_data.get("image", ""),
            }
        )

    @classmethod
    def from_polygon_response(
        cls,
        symbol: str,
        article_data: Dict[str, Any]
    ) -> "RawNewsItem":
        """
        Create RawNewsItem from Polygon API response.

        Args:
            symbol: Stock ticker symbol
            article_data: Article data from Polygon

        Returns:
            RawNewsItem instance
        """
        # Extract published_at from Polygon's 'published_utc' field (ISO string in UTC)
        # Store as naive UTC (Supabase will treat as UTC)
        published_at = None
        if 'published_utc' in article_data:
            utc_time = datetime.fromisoformat(article_data['published_utc'].replace('Z', '+00:00'))
            published_at = utc_time.replace(tzinfo=None)

        return cls(
            symbol=symbol.upper(),
            raw_json=article_data,
            url=article_data.get("url", ""),
            fetch_source="polygon",
            published_at=published_at,
            metadata={
                "external_id": article_data.get("id", ""),
                "author": article_data.get("author", ""),
                "publisher": article_data.get("publisher", ""),
                "image_url": article_data.get("image_url", ""),
                "amp_url": article_data.get("amp_url", ""),
                "tickers": article_data.get("tickers", []),
            }
        )

    class Config:
        """Pydantic config."""
        use_enum_values = True
